% Chapter 1

% variables
\newcommand{\pdirone}{chapters/plots/chapter1}

\chapter{Introduction}

\label{chapter1}

In this first chapter, we briefly review the concept of Dark Matter (DM). In Sec.\ref{ch1:sec:dm-evidence} we will explore why we need DM, and what are the alternatives to it. After that, we will come to realize that Dark Matter hides an extremely large number of possibilities that can be constructed using the framework of Quantum Field Theory (QFT). Dark Matter candidates are indeed very numerous, so we will focus on the most relevant ones within the scope of this thesis in Sec.\ref{ch1:sec:dm-candidates}.

The main focus of my thesis will be the so-called Dark Sector, where Dark Matter particles can interact with the Standard Model using new undiscovered interactions. We will describe this framework in Sec.\ref{ch1:sec:dm-sector}  by introducing the vector portal, which postulates the existence of an additional $\textrm{U(1)}$ symmetry that generates a dark vector boson part of a new "Dark Sector" . The vector gauge boson generated by this symmetry, that we will label out $\DM$ through this thesis,  is frequentl called Dark Photon, since it plays an equivalent role of the Standard Model (SM) photon in this new symmetry. This model allows also a cross-term that couples the new Dark Photon with its SM counterpart, effectively building a portal between the two sectors. If such a model is true, we can produce this type of matter using modern accelerators. An introduction to the framework of thermal Dark Matter will then be given. We will see that the Dark Sector, and in particular the vector portal, is an interesting candidate to explain the observed relic density using the freeze-out mechanism. This further motivates using accelerators experiments to probe the mass range Mev-GeV, which is very challenging to cover using other approaches.

After this introduction, we will see how Dark Matter can be searched for using particle beams in the context of fixed-target experiment. Starting from the benchmark model $\umodel$, the signal yield expected in such experiments is derived for different decay modes. The production of Dark mediators in accelerators is not limited however to vector bosons only, but can be extended to a large group of models that predicts interactions between the Dark Sector and particles from the SM. Some of these additional searches, like the one for axion and axion-like particles, were already performed by NA64 as will be presented in this thesis.
Another phenomenon that could be explained in this framework is the so-called $\DMX$-anomaly, originally known with the name of $^8$Be-anomaly. This refers to a deviation from the SM prediction in the nuclear decay spectrum of Beryllium that could be justified by the existence of a new particle. In Sec.\ref{ch1:sec:dm-u1model-motivations-x17} a review of this phenomena will be given, and we will show how particle physics explanations of this anomaly are within the sensitivity range of the NA64 experiment.

%----------------------------------------------------------------------------------------

\section{The Standard Model and its challenges}
\label{ch1:sec:sm-puzzles}

The Standard Model (SM) is the theory that to this date best describes our current understanding of particles and their interaction. It was developed in the second half of the 20th century, and reached its currently accepted formalism with the introduction of the Higgs mechanism \cite{PhysRevLett.13.508} in the electro-weak interaction \cite{PhysRevLett.19.1264}. SM describes matter and energy in terms of interactions between elementary particles, which are turn constructed as excitation of quantum fields. The theory contains 12 fermions\footnote{and their corresponding anti-particles} and gauge bosons that mediate the 3 fundamental interactions\footnote{Gravitation, is not included in this framework, and is instead described by General Relativity.} between particles: strong, weak and electromagnetic. These bosons are generated by symmetries described by unitary product groups:

\begin{equation}
    \label{eq:sm-group}
    \underbrace{\rm{SU(3)_c}}_{\textrm{strong interaction}} \times \underbrace{\rm{SU(2)_L}}_{\textit{weak interaction}} \times \underbrace{\rm{U(1)_Y}}_{\textit{em interaction}}
\end{equation}

A complete review of the Standard Model is beyond the scope of this introduction, and can be found instead in \cite{review-particle-physics}. The SM is incredibly successful, e.g. anticipating the existence of the W and Z boson, the gluons, and the top and charm quarks \cite{Woithe_2017}. The recent discovery of the Higgs boson \cite{Aad:2012tfa} completed the set of elementary particle predicted by the theory. Outstanding quantitative predictions were also performed within this framework, especially using Quantum ElectroDynamics (QED).  One of the most famous example is the exact value of the anomalous magnetic moment of the electron, that agrees within one part per billion with the experimental measurements \cite{Mohr:2015ccw}.

So why are physicists still unhappy with SM regardless of its undeniable successes? There are still many problems with the Standard Model that are not well understood and a source of debate within the scientific community. First of all it does not include a description of gravitation, being incapable to explain General Relativity in terms of a quantum field theory. This alone underlines that SM has not the requirements to be a theory of everything and that a piece must still be missing. On top of that, the Higgs mechanism gives rise to a Hierarchy problem \cite{review-particle-physics}, since its measured mass is much lighter than what anticipate by its quantum corrections unless an incredibly large fine-tuning is argued to fix this prediction.

There is however something that makes the need for a new theory even more apparent. The Standard Model explains the existence of only a tiny portion of the matter in the universe! Approximately only 5\% of the total mass observed. To explain this discrepancy, the $\Lambda$CDM\footnote{Stands for $\Lambda$ Cold Dark Matter, where $\Lambda$ represents the cosmological constant associated with Dark Energy.} is commonly used.  It is often referred to as the "Standard Model of Cosmology" because its predictive power is arguably comparable to its particle physics counterpart for cosmological observations. However, this model assumes the existence of particles which are not yet experimentally observed, and are not predicted by the Standard Model! This class of particles is called Dark Matter, one of the greatest puzzle of modern physics.

\section{Evidence for Dark Matter}
\label{ch1:sec:dm-evidence}

The history of Dark Matter and the birth of this term is interesting on its own, and a good example of "unequivocal accumulated evidence" in science \cite{hooper, deSwart:2017heh}. The term was first used in 1937 by astronomer Fritz Zwicky\footnote{Some weaker claim of a discrepancy was observed even before by Knut Lundmark in 1930.} to justify the velocity dispersion in Coma cluster galaxies which deviated significantly from what one would expect by simply asserting the mass from the visible matter \cite{1933AcHPh...6..110Z}. This hypothesis was discussed more seriously in 1950 when astronomical surveys had confirmed these results with high precision. This sparked a heated debate in the scientific community, and most solutions to this problem did not include additional unknown matter, but rather the modification of gravity or  sophisticated arguments based on the dynamical equilibrium of such galaxies. In 1970, with the rising of radio astronomy, the rotation curves of galaxies were studied in detail, and two independent observations, performed by Kenneth Freeman and Vera Rubin, confirmed that the rotation velocity of objects in a galaxy becomes flat at sufficient distance from its center. The idea became very influential in the cosmological community thanks to two papers in 1974 by Einasto and Ostriker, clearly stating that the mass of galaxies has been underestimated by a factor 10 until then \cite{EINASTO1974,1974ApJ...193L...1O}. This was further strengthened by the end of the decade by a very similar analysis \cite{annurev.aa.17.090179.001031}. The existence of Dark Matter became more and more accepted in the years to come, alternative theories also arose to explain observation without the need of additional matter. Perhaps the most famous today remains the Modified Newtonian Dynamics (MOND) theory, built as a weak-field approximation of some more general theory of gravity yet to be discovered. Despite an early success, this theory has always proven to be challenging to merge in the general relativity framework, and is insufficient to justify some specific phenomena like the famous "bullet cluster", that is on the other hand very well explained by Dark Matter \cite{Clowe_2006}.

So what is the current situation? Today the theory is well accepted in the scientific community, although some debate is still present. The existence of Dark Matter is the leading paradigm to explain all discrepancies observed \cite{hooper}. Advances in the field of cosmology and measurement techniques have provided much more evidence that aid Dark Matter existence. For example, gravitational lensing, in particular in the context of weak lensing, was used to characterize the mean distribution of Dark Matter and match it to the one predicted by large scale structure measurements \cite{weak-lensing}. Temperature anisotropies of the Cosmological Microwave Background (CMB) also present structures compatible with Dark Matter, and well fitted in the $\Lambda$CDM model \cite{Ade:2015xua}. Many other arguments, including structure formation \cite{Navarro:1995iw}, baryon acoustic oscillation \cite{bao}, and Red-shift distortions \cite{Peacock2001} have proven consistently to agree with the existence of Dark Matter and with the Lambda Cold Dark Matter ($\Lambda$CDM) model in particular.

While the consensus on the DM  existence is now well established, its origin and exact composition is still a big mystery. In the next section, we will give an overview of what exactly defines Dark Matter, starting from its measured properties. After that, we will explore the most popular models which try to address this puzzle.
%So let us assume like the majority of the scientific community that Dark Matter indeed exists, what is its exact nature? Can we point down some characteristics and a space of parameter that defines it exactly? Those are the questions that will be answered in the next section.

\section{Dark Matter candidates}
\label{ch1:sec:dm-candidates}

The first question to ask ourselves is what kind of property Dark Matter should have to satisfy the experimental constraints given by cosmology. We can define the following key characteristics \cite{Profumo:2019ujg}:

\begin{itemize}
\item \textit{Dark}: It should not emit/absorb light, but a tiny charge is still compatible with data. This justifies e.g. models predicting "milli-charged" particles. What is effectively constrained is the ratio of charge to a power of the mass.
\item \textit{Collisionless}: Dark Matter self-interaction to mass ratio is constrained by observation of cluster mergers and the ellipticity of galactic halos. The cross-section itself is not however necessarily small. Assuming a mass similar to the one of a proton, the constraint amount to a cross-section in the order of a few barn, very similar to the one observed for the strong interaction.
\item \textit{Classical}: Dark Matter is observed to be confined on the galactic scales of a few kpc in dwarf galaxies. Hence, their de Broglie length must be smaller than that to have a coherent Dark Matter halo. This argument is typically used to put a lower limit on the DM mass. If the Dark Matter candidates is a fermion, constraints are stronger as Pauli blocking limits the density to at most the phase space density to $f=gh^{-3}$ where $g$ is the number of internal degrees of freedom.
\item \textit{Fluid}: For macroscopic DM, with a mass much larger than the solar mass $M_{\odot}$, tidal disruption is expected to break the stability in a globular cluster. This limit is typically placed around $10^6 M_{\odot}$.
\end{itemize}

In summary, while the cosmological and Galactic Dark Matter density is known to a good degree, very weak constraints exist on  possible interaction strength (in addition to gravity) and the exact mass of Dark Matter. The huge mass scale that spans over the possible region is depicted in Fig.\ref{fig:dm-mass-range}, where we see several possible DM candidates in relation to their mass and the different techniques to probe them. A few experimental anomalies are labeled in red to see mismatches between theory and experiment that could potentially be explained by Dark Matter. We can see that most of them are in the $\mev$-$\gev$ scale, which is the one covered by the NA64 experiment. Even the problem of the cosmological scale, like small-scale structure, are potentially well explained by this class of models \cite{battaglieri2017cosmic}.

\begin{figure}[bht!]
  \centering
  \includegraphics[width=\textwidth]{\pdirone/DM_summary.pdf}
  \caption[Mass range for Dark Matter]{Mass range for Dark Matter and mediator particle candidates, experimental anomalies, and search techniques.}
  \label{fig:dm-mass-range}
\end{figure}

Because of the relatively loose constraints, it comes to no surprise that a vast amount of models have been theorized for the explanation of DM. The ones depicted in Fig.\ref{fig:dm-mass-range} are only a subset of what is currently considered. Models can also be extended to include scales not admitted in their original incarnation. It is the case for Axion Like Particles (ALPs), that are an extension of the QCD Axion model originally developed to solve strong CP problem \cite{PhysRevD.16.1791}. Contrary to Axions, their mass $m_a$ is taken as an independent parameter from their main coupling $g_{a \gamma \gamma}$. ALPs mass can  be in the $\mev$-$\gev$ scale, in the range where the NA64 experiment is sensitive. As we will show in Sec.\ref{ch4:sec:exclusion-limits}, we already used our data to constraint a portion of this parameter space \cite{Banerjee:2020fue}.

A description of each single model of DM is out of the scope of this thesis. For a complete review, one can refer to \cite{battaglieri2017cosmic,Profumo:2019ujg,HAMBYE2020135553,alex2016dark,review-particle-physics,Feng:2010gw}. Here, we provide a short description of the mainstream possibilities currently considered for Dark Matter:
\begin{itemize}
\item \textbf{\textit{WIMP}}: For a long time, Weakly Interacting Massive Particles (WIMP) were considered the most probable candidate by the scientific community. Their main characteristic is tree-level interaction with the W and Z boson, but not with gluons or photons. Historically, their mass is in the 10 \gev-\si{\tera\electronvolt}, although more recent models extended the mass range to lower masses as well. The so-called WIMP miracle \cite{Chang:2013oia}, provided a very effective and natural way to introduce Dark Matter in the thermal history of the early universe in a way that predicted precisely the current relic density. However, after an extensive amount of research, accelerators and direct searches have to this date failed to provide evidence for their existence \cite{Arcadi:2017kky}. These models have yet to be ruled out completely and remain the most studied type of Dark Matter.
\item \textbf{\textit{Axions and Axion-like}}: Axion and Axion-like particles are obtained by introducing a new pseudoscalar field $a$ with coupling to photons, gluons, or Higgs bosons \cite{Marsh:2015xka}. Originally Axions were motivated by the strong CP problem and they were predicted to be extremely light ($<$\si{\electronvolt}). The model was later extended to offer a possible explanation for Dark Matter at higher masses. Several experiments are based on the "light shining through a wall" concept or using a magnetic helioscope \cite{annurev.nucl.56.080805.140513} already put some stringent limits on Axions. Axion-like particles on the other hand can have a mass large enough to allow testing using accelerators.
\item \textbf{\textit{Sterile Neutrino}}: While Standard model neutrinos are not a good fit to explain Dark Matter as they are produced very hot in the early thermal bath, Sterile neutrinos are on the other hand a viable explanation. A subset of these models can also explain the light neutrinos masses as a consequence of the \textit{see-saw} mechanism, although they are not favored as Dark Matter explanation \cite{Feng:2010gw}. 
\item \textbf{\textit{Dark Sector}}: By the name of Dark Sector, we describe a very large class of models characterized by particles not charged directly under strong, weak, or electromagnetic force \cite{alex2016dark}. Dark Matter can still interact with the SM particles through so-called "portal interactions" constrained by the symmetry of the SM. This class of models, specifically the ones charged under a new U'(1) symmetry, are the focus of the NA64 experiment, and they will be described in more detail in the next sections.
\end{itemize}

\section{Dark Sectors}
\label{ch1:sec:dm-sector}

Dark sectors are very interesting candidates to explain the origin of Dark Matter (see \cite{battaglieri2017cosmic,alex2016dark} for recent reviews). On top of reproducing the observed DM abundance in freeze-out or freeze-in scenarios, many experimental anomalies currently observed can be explained inside this framework. The anomalous magnetic moment of the muon \cite{blum2013muon}, the proton charge radius\footnote{Recent new measurements suggest that this puzzle can be solved without new physics \cite{Karshenboim2019}} \cite{Pohl2010} and more recently the $\DMX$-anomaly \cite{Krasznahorkay:2015iga,Krasznahorkay:2019lyl} have been suggested as possible hints of its existence \cite{alex2016dark}. The definition of Dark Sector is extremely broad, and therefore accommodates many possible models. Its physics however, can be explored effectively and in a systematic way by using specific portal interaction as a classification scheme.  The existence of a mediator acting as a portal is not a necessity to create a Dark Sector, but a small interaction with SM allows a signature in particle physics experiments as well as a mechanism to compute the observed relic density \cite{prw, pospelov}. The gauge and Lorentz symmetries restricts the ways in which the mediator can couple to SM particles. We can classify them using their spin and parity. By excluding dimension operators larger than 5 we obtain four renormalizable possibilities \cite{alex2016dark}:

\begin{equation}
  \label{eq:dm-portals}
  \mathcal{L} \quad \supset \quad
\begin{aligned}
  &-\frac{\epsilon}{2 \cos{\theta_W}}B_{\mu \nu}F'^{\mu \nu}, &\textrm{vector portal}\\
  & (\mu \phi + \lambda \phi^2)H^{\dagger}H, &\textrm{Higgs portal}\\
  &y_n LHN, &\textrm{neutrino portal} \\
  &\frac{a}{f_a} F_{\mu \nu} F^{\mu \nu}, &\textrm{axion portal}
\end{aligned}
\end{equation}

In this work, we will limit the discussion on the vector portal, as it is the most viable for thermal models of Light Dark Matter (LDM). If we assume the DM mediator to be a vector boson arising from an additional U'(1) gauge group under which the LDM is charged, we can derive a term $\epsilon / 2 \cos{\theta_W} B^{\mu \nu} F'{\mu \nu}$ that is invariant both on this symmetry and the standard U(1) from QED. This can be used to explain the phenomenology of a large class of models, such as scenarios where the Dark Photon couples preferentially to Baryonic (B), Leptonic (L), or (B - L) currents. One such case, where the coupling to Baryon is disfavored, is the protophobic $\DMX$ gauge boson \cite{PhysRevD.95.035017}, that will be introduced at the end of this chapter. Other possibilities include the LDM possessing a Majorana mass in the absence of an exact $\rm{U)1}$ symmetry \cite{PhysRevD.93.063523}, or the existence of a rich sector where many particles exist on top of the Dark mediator and the LDM \cite{Morrissey_2014}.

\subsection{Thermal Dark Matter and Dark Sector}
\label{ch1:sec:thermal-dm}

To justify the Dark Matter density observed today, a model that describes the production of such particles in the early universe is commonly used. Such a model is not only useful to describe the dynamic of the universe but can also provide some constraints on the properties of Dark Matter, allowing us to restrict our searches to a class of models that obeys these conditions. Arguably the most popular framework of this kind describes Dark Matter as a thermal relic generated in the early universe thermal bath. In this environment, DM is produced in the direct annihilation $SM+SM \to DM+DM$. For this interaction to take place, the energy of the SM particles needs to be sufficient to produce the mass of the DM candidate. After the universe cools down to a temperature $T$ below the dark matter particle mass $m_{DM}$, the number of Dark Matter particles becomes Boltzmann suppressed, dropping as $e^{- T / m_{DM}}$ \cite{Feng:2010gw}. Such mechanism is called "freeze-out" and is based on the decoupling of DM particles from the SM caused by the universe cooling down to a temperature where the DM production becomes inefficient. The exact relic density is then obtained by solving numerically the Boltzmann equation:

  \begin{equation}
    \label{eq:boltzman-equation}
    \frac{d n}{d t} = -3 H n - \langle \sigma_A v \rangle (n^2 - n^2_{eq})
  \end{equation}

  where $n$ is the number density of DM particles, H is the Hubble parameter,  $\langle \sigma_A v \rangle$ is the thermally averaged cross-section, and $n_{eq}$ is the Dark Matter number density in thermal equilibrium. One can use the above formula to calculate the observed relic density, which will depend on the exact value of the cross-section of direct annihilation. As the annihilation cross-section is in many theories determined exclusively by the mass $m_{\chi}$, the two parameters can be matched using this framework. If we assume a weak interaction between DM and SM, for example, we get the formula \cite{Feng:2010gw}\footnote{An additional factor of $v^2$ multiplies the right-hand side of the equation if we assume P-wave annihilation.}:

  \begin{equation}
    \label{eq:dm-fo-sigma}
    \sigma_A v = k \frac{g^4_{weak}}{16 \pi^2 m^2_{\chi}}
  \end{equation}

  Which can be used to match the mass $m_{\chi}$ directly to the relic density observed in the present universe. WIMPs make an excellent Dark Matter candidate for this reason: a new particle in the mass range of 100 \gev - 1 \si{\tera\electronvolt} interacting weakly can easily account for all Dark Matter observed. There are many different caveats to this model that we skipped here, and many alternative mechanisms were proposed \cite{Hall:2009bx,Feng:2010gw,Marsh:2015xka,Griest:1990kh,Arcadi:2017kky}. Nevertheless, WIMPs remain very popular candidates in the freeze-out frameworks, but the many negative results obtained by direct detection experiments and so far no sign Supersymmetry (SUSY) at LHC would suggest that a wider range of masses should be explored as well. This provides an excellent motivation for the Dark Sector, where a Lightest Thermal Dark Matter (LTDM) is stable and produced in the early universe via one of the portals described in the previous section. The Dark Sector accommodates a wider range of masses compared to WIMPs (see Fig.\ref{fig:dmplane-overview}). Particles in the mass range 1 $\mev$ - 10 $\gev$ are however hard to probe using direct detection experiments, as the energy recoil from the scattering of a thermal relic with a nucleus becomes too small to be measured by standard detectors\footnote{Methods to lower the threshold are however being developed, which would allow also such experiments to extended their sensitivity to sub-\gev particles \cite{Baracchini:2020nut}.}. Accelerator experiments are on the other hand sensitive to these masses, and have the advantage of a production rate independent from the exact details of the Dark Sector predicted from the freeze-out mechanism \cite{battaglieri2017cosmic}. This cross-section can be computed for a generic Dark Sector portal. We assume a mediator MED to be present together with a generic LTDM with mass $m_{LTDM}$ which can account for the relic density. If we define $g_{SM}$ as the SM-mediator coupling we obtain:

  \begin{equation}
    \label{eq:dm-cs-fo}
    \langle \sigma v \rangle = \frac{1}{6\pi}\frac{g^2_D g^2_{SM} m^2_{LTDM} v^2}{(m^2_{MED} - 4m^2_{LTDM})^2 + m^2_{MED}\Gamma^2_{MED}}
    \end{equation}

    
    Where we assumed $v \ll c$ and $m_e \ll m_{LTDM}$. If we further assume to be away from the resonance region $m_{MED} \approx 2m_{LTDM}$ and $m_{MED} \gg \Gamma_{MED}$, the cross-section only depends on the mass of the LTDM and the dimensionless parameter:

    \begin{equation}
      \label{eq:dmplane-y}
      y = \frac{g^2_D g^2_{SM}}{16 \pi^2} \left( \frac{m_{LTDM}}{m_{MED}} \right)^4
    \end{equation}

    To be compatible with a freeze-out mechanism, a lower bound must be defined on the direct annihilation cross-section, which can be translated in a minimum value of $y$. A larger value of $y$ is also possible and describes models where the direct annihilation is not the dominant process that describes the relic abundance \cite{battaglieri2017cosmic}. This way we obtained a well-defined parameter space where to search for Dark Matter and a powerful method (accelerators) to explore it. In the next section, we will study the vector portal in more detail, and develop the most relevant formulas needed for the production and detection of the mediator. In the study that follows, we will assume a Dirac spinor as LTDM. Accelerator experiments, however, can probe many possible candidates, like complex scalars and axially coupled Majorana fermions. A detailed classification of mediators and LTDM in the Dark Sector can be found in \cite{PhysRevD.92.123531}. The lower limit of $y$ predicted for several interesting cases is presented in Fig.\ref{fig:dmyplane-base}.

    \begin{figure}[bth!]
      \centering
      \includegraphics[width=\textwidth]{\pdirone/dmyplane_base.pdf}
      \caption[Lower limit of $y$ in dark sector]{Lower limit of $y$ motivated by thermal freeze-out as function of the mass of the LTDM in the context of Dark Sector. The limit is shown for scalar relic, Majorana fermion, Pseudo-Dirac fermion (black line). The scenario of asymmetric fermion Dark Matter is also shown (grey line), which is a common variation of the classical thermal-origin framework \cite{battaglieri2017cosmic}.}
      \label{fig:dmyplane-base}
    \end{figure}

\subsection{The vector portal}
\label{ch1:sec:dm-colliders}

The vector portal is built by introducing an additional $\umodel$ symmetry to the standard model Lagrangian:
\begin{equation}
  \label{eq:dm-lagrangian}
  \mathcal{L}_{DS} = \mathcal{L}_{SM} \underbrace{- \frac{1}{4}F'_{\mu \nu}F'^{\mu \nu} + \frac{m_{\DM}}{2}A'_{\mu}A'^{\mu}}_{\textrm{U'(1)}} + \underbrace{i \bar{\chi} \partial_{\mu} \chi - m_{\chi}\bar{\chi}\chi - e_D \bar{\chi}\gamma^{\mu}A'_{\mu}\chi}_{\textrm{Dirac spinor}} + \underbrace{\frac{\epsilon}{2}F'_{\mu \nu} F^{\mu \nu}}_{\textrm{mixing term}}
\end{equation}
This new symmetry introduced an additional gauge vector boson $\DM$. Here we also added a Dirac spinor field $\chi$ that is coupled to $\DM$ by a coupling constant $g_D$. This is for the completeness of the model, which is also supposed to contain an LDM that justifies the relic density. Indeed the new parameters introduced in the Lagrangian can be used to describe the value of $y$:

    \begin{equation}
      \label{eq:dmplane-y-dp}
      y = \alpha_D \epsilon^2 \left(m_{\chi}/ m_{\DM} \right)^4 
    \end{equation}

which can be used to cast results in the parameter space relevant for a freeze-out scenario.
The part of the Lagrangian over the first parenthesis is the one generated by the new U'(1) symmetry and is the most relevant to compute the physics of the portal. In particular, the term multiplied by $\epsilon$ represents the kinetic mixing between $\gamma$ and $\DM$, as it multiplies the two field tensors generated by the two U(1) groups. Here $\epsilon$ is taken as an a priori parameter that controls the strength of the kinetic mixing. it can in principle take any value, but being naturally generated inside loops of heavy fields charged under both symmetries, it is expected to be small, in the range $\epsilon \sim 10^{-8} - 10^{-2}$ \cite{jdb}. 

The channels that allow the production of this new boson $\DM$ are similar to the ones that can be used for $\gamma$ as they both are the generators of a U(1) symmetry. In first order they are the following:

\begin{itemize}
\item \textit{Dark Bremsstrahlung}: The reaction $\darkbrem$ where $\DM$ is emitted after a virtual photon is exchanged with a target nucleus $Z$.
\item \textit{Dark Compton}: The reaction $\darkcompton$, where $\DM$ is produced as a consequence of the interaction of a photon and an electron.
\item \textit{Dark Resonance}: The reaction $\darkresonance$ where two leptons annihilate and produce an $\DM$ as a consequence of a resonance.
\item \textit{A-resonant Emission}: The emission of $\DM$ is also possible without a resonance with the additional emission of a photon via the interaction $\darkaresonance$.
\end{itemize}

The Feynman diagrams of all processes mentioned above are depicted in Fig.\ref{fig:dm-production-mechanism}.

\begin{figure}
\centering
\includegraphics[width=.45\textwidth]{\pdirone/DarkBremstrahlung.png}
\includegraphics[width=.45\textwidth]{\pdirone/DarkCompton.png}
\includegraphics[width=.45\textwidth]{\pdirone/DarkResonance.png}
\includegraphics[width=.45\textwidth]{\pdirone/DarkAresonance.png}
\caption{Possible production mechanism for $\DM$: Dark Bremsstrahlung a), Dark Compton b), resonance production c) and A-resonant production d).}
\label{fig:dm-production-mechanism}
\end{figure}

Other channels might be possible with minimal extension of the model, or one could find a significant yield of production not only in the scattering of an electron but also using another type of primary. An example would be using the electromagnetic portion of a large hadron shower to compute the yield of $\DM$, which was suggested as a possible future method to search for low mass $\DM$ in \cite{Celentano:2020vtu}.

When a high energy particle hits a thick target, all of the mentioned mechanisms will be relevant to some degree.
In most fixed-target experiments, however, the Dark Bremsstrahlung $\darkbrem$ is used as the "Golden Channel" of production because of its good yield compared to the other channels. The other types of productions mechanism described are considered corrections to a production rate mostly dominated by this interaction. A dedicated setup, however, might make other contributions relevant as well. An example is found in \cite{Marsicano_2018}, where the non-resonant and resonant production are used to improve significantly the signal yield for a specific mass range.

After the production mechanism is chosen, some first estimate on the signal yield can be performed. However, successfully producing the particle is not by itself sufficient without a way to detect it. The question is: what happens to $\DM$ after it is produced inside a target? Since a coupling between standard matter and dark matter was theorized in the $\umodel$ model, the $\DM$ will be able to decay in a $\ee$ pair (or in more massive leptons) provided that its mass is sufficiently large, but it could also decay in particles of the dark sector $\dmchi$. It is important to know that there is no meaningful constraint that prevents both branching ratios to be of the same magnitude. Likewise, models with more complicated decays are possible as well. An example is the one described in \cite{Mohlabeng_2019}, where the decay chain $\dmsemivis$ dominates. 

\subsection{Dark Photon production in fixed-target experiments}
\label{ch1:sec:dm-u1model}

In this section, the Dark-Bremsstrahlung channel will be described by studying the specific case of an electron impacting on a fixed-target. The main formulas to calculate the rate of production and detection are developed starting from the Lagrangian. In terms of production rate inside a fixed-target, the $\umodel$ model is only defined by the mass of the mediator $m_{\DM}$ and the strength of the coupling $\epsilon$, and hence the parameter space of these hypotheses is characterized by the plane $\dmplane$. The mixing term generates the interaction:

\begin{equation}
  \label{eq:dm-interaction}
  \mathcal{L}_{int} = \epsilon e A'_{\mu}J'_{em}
\end{equation}

between the Dark photon and the ordinary matter. The Dark Photon is produced as Dark Bremsstrahlung in the process $e^- Z \to e^- Z \DM$.

Calculating this cross-section is challenging due to complicate integrals involving nuclear effects. We instead assume that the mass of $\DM$ is large enough to treat the $\gamma$ exchanged in the reaction as a physical photon instead of virtual one, which allows us to reduce the problem to the scattering of the electron with a physical photon emitted by nucleus. This is called the Weizsacker-Williams (WW) approximation \cite{Kim:1973he}, and yields to the result \cite{jdb}:

\begin{equation}
  \label{eq:dm-diff-cross}
  \frac{d\sigma}{dxd\cos{\theta_{\DM}}} = \frac{8 Z^2 \alpha^3 \epsilon^2 E^2_0}{\textrm{U}^2} \mathcal{L}og \times \left[ (1 - x + x^2/2) - \frac{x(1-x)m^2_{\DM}E^2_0 x \theta^2_{\DM}}{\textrm{U}^2} \right]
\end{equation}

where $E_0$ is the energy of the incoming electron, $E_{\DM}$ is the energy of the emitted $\DM$, $\theta_{\DM}$ is the angle of emission in the lab frame, and $Z$ is the atomic number of the nucleus. $x=E_{\DM}/E_0$ is the fraction of original energy transferred to the Dark Photon, the $\mathcal{L}og \sim 5 - 10$ is a factor accounting for atomic screenings and nuclear size effects (see Appendix.\ref{appA:sec:cross-section-wz}). The function $U$ defines the virtuality of the incoming electron in the intermediate state of the Bremsstrahlung, defined as:

\begin{equation}
  \label{eq:u-func}
  \textrm{U} = E^2_0 x \theta^2_{\DM} + m^2_{\DM} \frac{1 - x}{x} + m^2_e x
\end{equation}

We continue by performing the angular integral on Eq.\ref{eq:dm-diff-cross}:

\begin{equation}
  \label{eq:dm-diff-cross-int}
  \frac{d\sigma}{dx} \approx \frac{8 Z^2 \alpha^3 \epsilon^2 x}{m^2_{\DM}} \left( 1 + \frac{x^2}{3(1-x)} \right) \mathcal{L}og 
\end{equation}

Now we can apply this formula to compute the yield inside a target. If we assume an electron with energy $E_0$ impacts a thick target with total radiation length $T$, we derive:

\begin{equation}
  \label{eq:dm-general-yield}
  \frac{dN}{dx} = N_e \frac{N_0 X_0}{A} \int_{E_{\DM}}^{E_0} \frac{dE_1}{E_1} \int_0^T dt I(E_1;E_0;t) \times E_0 \frac{d\sigma}{dx'}\Big|_{x' = E_{\DM}/E_1}
\end{equation}

where $N_0$ is the Avogadro's number, $X_0$ is the radiation length of the target, $A$ is the target atomic mass, and $I$ is the energy distribution of electrons after passing through $t$ radiation lengths. The above integral is still fairly complicated, mainly an accurate description of the electron energy distribution after $t$ radiation lengths is not an easy task\footnote{In practice, this is solved by MC-simulation as we will see in chapter \ref{chapter3}}. A common approach is the thin target approximation, where $I \approx \delta (E_1 - E_0)$ is used as the target is assumed to be thin enough that no electromagnetic shower (em-shower) is triggered. In fixed-target experiments however, is desirable to block the incoming $e^-$ completely to suppress the background, which means a thick target is used instead. This requires some additional care in parametrizing $I$ as illustrated in Appendix.\ref{appA:sec:production-rate}. Here we report the final results, the rate at which the $\DM$ is produced is approximated by:

\begin{equation}
  \label{eq:dm-rate}
  N_{\DM} \simeq N_{EOT} \times C' \epsilon^2 \frac{m_e^2}{m^2_{\DM}}
\end{equation}

This allows us to calculate the number of Dark Photon produced as a function of the accumulated EOT (Electrons On Target). The dimensionless factor $C' \approx 10$ is obtained after solving the integral. One has to be careful with this formula since many approximations were used to derive it and is expected to be accurate within an order of magnitude \cite{jdb}. However, it provides us with some very useful scaling with the parameters of the model and allows us to understand the sensitivity of the experiment plotted in the $\dmplane$ space. To compute the exact sensitivity with high precision, a detailed MC-simulation should be used instead.

\subsubsection{Decay modes and detection}
\label{ch1:sec:dm-decay}

After the production of $\DM$, a mechanism to detect it is needed. To address this problem, we need to understand what happens to $\DM$ after is emitted inside the target. In our model a Dirac field is also present, so the Dark Photon can in principle decay in a pair of particles generated by this field, which are stable LTDMs. However, a decay in SM leptons is also possible, since the kinetic mixing mechanism can act in both directions. This provides two different decay channels, which will define the precise detection strategy. We compute the two decay rates starting from the interaction Lagrangian in Eq.\ref{eq:dm-interaction}. We obtain:

\begin{equation}
  \label{eq:dm-bratio}
  \begin{aligned}
    &\Gamma(\DM \to \bar{\chi} \chi) = \frac{\alpha_D}{3} m_{\DM} \left( 1 + \frac{2m^2_{\chi}}{m_{\DM}^2}\right) \sqrt{1 - \frac{4m_{\chi}^2}{m^2_{\DM}}}\\
    &\Gamma(\DM \to l^+l^-) = \frac{\alpha \epsilon^2}{3} m_{\DM} \left( 1 + \frac{2m^2_{l}}{m_{\DM}^2}\right) \sqrt{1 - \frac{4m_{l}^2}{m^2_{\DM}}}
  \end{aligned}
\end{equation}

For completeness, the visible mode decay is written in a general way that accounts for any lepton pair. By looking at the leptons of the SM, we can conclude that the decay $\aee$ will be the most relevant since for muons it is suppressed by a factor $(m_e/m_{\mu})^2 \approx 10^{-4}$ and no Dark Photon in the range of fixed-target experiments has enough mass to decay into a tau.

The two branching ratios above define two different regimes:
\begin{itemize}
\item \textbf{\textit{Invisible decay regime}}: If $\alpha_D \gg \alpha \epsilon^2$, the branching ratio of the invisible decay is dominant, hence the Dark photon will decay $\DM \to \bar{\chi} \chi$. This decay is characterized by missing momentum inside the target, as the $\dmchi$ cross-section of interaction is extremely low. In classical beam-dump experiments, the interaction is measured by a detector placed after the target, but this additional interaction is suppressed by a factor $\sim \alpha_D \epsilon^2$ for a total rate of $N_{\DM} \sim \epsilon^4 \alpha_D$, smaller if compared to Eq.\ref{eq:dm-rate}. In NA64, missing energy is used instead to characterize this decay channel.
\item \textbf{\textit{Visible decay regime}}: If $\alpha_D \ll \alpha \epsilon^2$, the branching ratio of the visible decay is dominant, specifically the decay $\aee$. The Dark Photon will travel for a short time without interaction and then decay into a $\ee$ pair, which can be detected after a thick wall. This concept is similar to a "Light shining through a wall" experiment popular for Axion searches, with the difference that is not a $\gamma$ but a $\ee$ pair that appears after the wall.
\end{itemize}

The NA64 experiment aims to cover both of these regimes, with slightly different setups to accommodate their different phenomenology. We need to study the two decay modes to see how the precise detection strategy will impact the total signal rate described by Eq.\ref{eq:dm-rate}.

In the case of an invisible decay, the signature is missing momentum in the setup. In principle, producing the $\DM$ is enough to detect it, as there will always be missing momentum as long as a Dark Photon is emitted. While this is true, one needs to estimate the amount of missing momentum needed for a clean signature. The actual fraction of energy missing required for a signal event in NA64 is $E_0/2$, i.e. half of the original beam energy. The answer to why this value is chosen requires proper accounting of the background, which will be given in chapter \ref{chapter3}.  For now, we just realize that our rate needs to be corrected by integrating the cross-section only to a specific energy value in Eq.\ref{eq:dm-general-yield}. From Eq.\ref{eq:dm-diff-cross} we know that the cross-section is peaked for $x \sim 1$ for any values of $\dmplane$, hence $\DM$ carries most of the original electron energy independently of the exact parameters of the theory. Some less trivial effects introduce some weak dependence on the exact model, but they can be in the first approximation excluded and calculated later using a detailed MC. Thus, the integration ultimately modifies slightly the numerical value of $C'$ in Eq.\ref{eq:dm-general-yield}, but do not introduce any additional scaling. In the case of invisible mode, this formula can still be used in good approximation to compute the final signal yield.

What about the visible mode? As for the previous case, we can argue that a minimum energy should be required to penetrate the target for a meaningful event. However, the $\DM$ needs also to travel outside the target to be visible, otherwise, the $\ee$ will just be absorbed inside the material. To compute this effect, we calculate the decay length of this particle in the laboratory frame:

\begin{eqnarray}
  L_{\DM} = \gamma c \tau \simeq \frac{3E_1}{m^2_{\DM}\alpha \epsilon^2} \simeq 28.3 ~{\rm mm}  \Bigl[\frac{E_{\DM}}{100~ {\rm GeV}}\Bigr] 
  \Bigl[\frac{17~ {\rm MeV}}{m_{\DM}}\Bigr]^2 \Bigl[\frac{10^{-3}}{\epsilon}\Bigr]^2
  \label{eq:dm-decay-length}
\end{eqnarray}

where we neglected the (small) phase space corrections and assumed only the $\aee$ is kinematically allowed. We assume also that $\DM$ is emitted always at the beginning of the shower with maximal energy $E_{\DM} = E_0$. The amount of $\DM$ that penetrates the dump can be computed by integrating the decay spectrum inside the fiducial-volume of the experiment, which starts from the end of the target and ends downstream where the first detector (in the NA64 case a scintillator used to tag the $\ee$ pair) is placed. We can multiply this fraction to Eq.\ref{eq:dm-rate}, and obtain the signal yield expected for the visible mode:

\begin{equation}
  \label{eq:dm-rate-vis}
    N_{\DM} \sim \underbrace{N_{EOT}}_{\textrm{beam-intensity}} \times \underbrace{C' \epsilon^2 \frac{m_e^2}{m^2_{\DM}}}_{\textrm{cross-section}} \times \underbrace{\left(e^{- L_{dump}/L_{\DM}} - e^{-L_{fiducial}/L_{\DM}}\right)}_{\textrm{decay length}}
  \end{equation}

  where we labeled each term by its source. The NA64 focus was set on bosons with a very small decay time, hence we explore the limit where $L_{\DM} \ll L_{Fiducial}$, where the second term becomes negligible. We finally obtain:

  \begin{equation}
    \label{eq:dm-rate-vis-limit}
    N_{\DM}^{(\aee)} \sim N_{EOT} \times C' \epsilon^2 \frac{m_e^2}{m^2_{\DM}} \times e^{-k\frac{L_{dump} m^2_{\DM}\epsilon^2}{E_0}}
  \end{equation}

  This means that the signal yield is exponentially suppressed for large masses and couplings. Increasing the beam-intensity here improves the sensitivity only logarithmically. The region of parameter space with these properties is also very interesting from the phenomenological point of view. An anomaly observed in the nuclear spectrum of a Beryllium isotope suggests that a particle with such properties might exist \cite{Krasznahorkay:2015iga}. As we will see in Sec.\ref{ch1:sec:dm-u1model-motivations-x17}, NA64 is sensitive to this hypothetical particle\footnote{A portion of this parameter space was already excluded by recent NA64 analysis \cite{Banerjee:2019hmi,Banerjee:2018vgk}.}, but the high coupling $\epsilon$ makes it hard to completely probe this model.

  \subsection{Dark Sector in accelerator experiments}

If the decay products are stable particles of the Dark Sector $\dmchi$, detecting them can be very challenging, as their interaction with matter is heavily suppressed. The NA64 experiment uses the missing-momentum technique described in the previous section, where the missing energy in an active target is used to define the signal region. This way, the setup requires only the Dark Photon to be produced but does not need a massive detector for its decay products. In this thesis, we will see that NA64 managed to extend the previous constraints of experiments at colliders by exploiting this method \cite{NA64:2019imj}. Other experiments using the same detection method are being designed for the future. The LDMX experiment, for example, aims to improve dramatically the sensitivity using the high-intensity electron beam at JLab \cite{Moreno:2019tfm}. An alternative strategy, frequently called beam-dump technique, consists of placing a thick detector downstream of the target and attempt to detect the $\chi$ produced in the $\DM \to \dmchi$ decay. This method essentially combines a classical direct detection experiment with the production of Dark Matter in an accelerator. This has the advantage of having a low background and a larger tolerance to high-intensity, as the detector is shielded by a very thick wall. However, looking at Eq.\ref{eq:dm-rate}, we see that in the case of an extra interaction an additional terms must be added for a correct account of the signal rate. This term can be computed in first order to scale as $\alpha_D \epsilon^2$, as the $\dmchi$ will use $\DM$ as a mediator to interact with a heavy nucleus. This additional factor reduces the sensitivity of the experiment to the parameter space characterized by small $\epsilon$, and contrary to the missing momentum method depends directly on the coupling of the Dark Sector $\alpha_D$, which also makes the method less sensitive to models that predict a small value of this parameter. An example of this kind is the E137 experiment \cite{e137}. The BDX experiment aims to use this technique and improve the previous results using the high-intensity electron beam at JLab and placing the detector closer to the dump \cite{Battaglieri:2019nok}.

To detect the visible decay products of $\DM$, the final state of $\ee$ is reconstructed by a tracking station placed after the thick target. An example of this is the APEX experiment at JLab \cite{apex}, which uses a high-resolution spectrometer placed after a high-Z target for the purpose. NA64 uses instead a thick active target made of Tungsten is for the production and a set of GEM trackers located in decay volume to reconstruct the decay vertex $\aee$. A second calorimeter is placed after the decay volume to measure the energy of the $\ee$ pair and match it to the one recorded by the active target.

Today, progress on experimental results started to put heavy constraints on the parameter space of Light Dark Matter candidates. NA64 is contributing to these efforts, excluding e.g. important models like the one capable of justifying the tension in the anomalous magnetic moment of the muon. Constraints have been placed by beam-dump \cite{jdb, charm, PhysRevLett.59.755, e137, konaka, PhysRevLett.67.2942, dav,  ath, nomad, e787, essig1, blum,sg1, blum1, sarah1}, fixed-target \cite{apex,merkel,merkel1}, colliders \cite{babar, curt, babar1}, rare particle decay searches \cite{sindrum, kloe, sg2, kloe2, wasa, hades, phenix, e949, na48, pol, kloe3} and the new determination of the fine structure constant $\alpha$ combined with the measurement of $(g-2)_e$ \cite{Parker191,PhysRevLett.100.120801}.

An overview of the parameter explored by the time this thesis is written can be seen in Fig.\ref{fig:dmplane-overview}.

\begin{figure}[bth!]
  \centering
  \includegraphics[width=\textwidth]{\pdirone/invisible-full-ps.png}
  \includegraphics[width=\textwidth]{\pdirone/visible-full-ps.png}
  \caption[Current exclusion limit and project for Dark Photon in the physics community]{Current limits and expected sensitivities of experiments for Dark Photon mediators decay either to LDM particles (top) or SM particles (bottom). The top figures assumes $\alpha_d = 0.1$ and $m_{\DM}/m_{\chi} = 3$ \cite{pbc-book}.}
  \label{fig:dmplane-overview}
\end{figure}  

\section{The X17 anomaly}
\label{ch1:sec:dm-u1model-motivations-x17}

A big boost to search for the new light boson weakly coupled to Standard Model particles was triggered by the recent observation of a 6.8$\sigma$ excess of events in the angular distribution of $\pair$ pairs produced in the nuclear transitions of the excited $^8$Be$^*$ nuclei to its ground state via IPC\footnote{Internal Pair Creation} of $\ee$ \cite{Krasznahorkay:2015iga}. The experiment used a proton beam to populate the isovector (17.6 \mev) and isoscalar state (18.15 \mev) 1$^+$ in the $^8$Be selectively using Lithium as initial target, and then detected the $\ee$ emitted in the reaction $^8$Be$^* \to ^8$Be using five plastic detector telescope in combination with position-sensitive MWPC\footnote{Multi-Wire Proportional Counters}. The concept of the experiment is depicted in Fig.\ref{fig:x17-setup} and a precise description of the setup can be found in \cite{GULYAS201621}.

\begin{figure}[htb!]
  \centering
  \includegraphics[width=\textwidth]{\pdirone/Atomki_setup.png}
  \caption[Sketch of the setup used to detect the $^8$Be anomaly.]{Sketch of the setup used to detect the $^8$Be anomaly. Lithium is bombarded by protons to excite the reaction $^7$Li$\to ^8$Be$^* \to ^8$Be. The aperture angle of the $\ee$ generate in the decay of the ground state is detected by a telescope made of five plastic scintillators. \cite{PhysRevD.95.035017}}
  \label{fig:x17-setup}
\end{figure}

While the spectrum of the isovector state showed good compatibility with the model, a substantial deviation was observed in the isoscalar state for angles $120 \si{\degree} < \theta_{\ee} < 160 \si{\degree}$. This deviation is challenging to explain in the context of nuclear physics \cite{Krasznahorkay:2015iga}, although some attempts can be found in \cite{Zhang:2017zap,Koch:2020ouk}. On the other hand, the anomaly can be easily interpreted as the emission of a gauge boson that mediates the $\ee$ pair at a specific energy. This hypothesis passes a good number of consistency checks. For example, since the mediator would be non-relativistic at these low energies, one would expect only $\ee$ pair with small asymmetry in energy to be effected as shown in Fig.\ref{fig:be-anomaly}. The effect of mediators with different masses was modeled using a MC-simulation, the best fit was found for $m_{\DMX} = 16.7 \pm 0.35^{\textrm{stat}} \pm 0.5^{\textrm{syst}}$ with an excellent compatibility of $\chi^2/\textrm{dof}$. Two years later, the same group investigated the anomaly using a new transition, the 21.01 $\mev$ $0^- \to 0^+$ in the $^4$He atom. The setup was improved with an additional scintillator and the MWPC substituted with a more precise  DSSD array\footnote{Double-sided Silicon Strip Detector}. The results of this experiment revealed a second anomaly compatible with what previously measured, estimating a mass of $16.84 \pm 0.16^{\textrm{stat}} \pm 0.20^{\textrm{syst}}$ \cite{Krasznahorkay:2019lyl}. The result is even more striking considering the fact that the angular correlation differs for this transition, where the peak appeared in the region $110 \si{\degree} < \theta_{\ee} < 130 \si{\degree}$, which makes it harder to explain the anomaly in terms of unknown systematics in the setup.

\begin{figure}[htb!]
  \centering
  \includegraphics[width=\textwidth]{\pdirone/X17_spectrum.pdf}
  \caption[$^8$Be anomaly]{On the left: angular spectrum of the $\ee$ pair created in the reaction $^8$Be$^* \to ^8$Be of the isoscalar state of Beryllium into the ground state using proton energies $E_p$ = 1.10 \mev. The curve is presented for both asymmetric and symmetric pairs, with a rescaling factor in the first case to separate the two curves. Simulations are shown for the expected spectrum (black lines) and the spectrum expected after adding a mediator of different masses (colored lines). On the right: the same spectrum is plotted as invariant mass, best fit (red), background predicted (blue dotted), and signal measured (green dotted) are presented as well. \cite{Krasznahorkay:2015iga}}
  \label{fig:be-anomaly}
\end{figure}

Clearly, the experiment will need a separate confirmation by a different group as suggested in \cite{Feng:2020mbt}, but in the meantime, several models are being proposed to describe this unknown mediator responsible for the anomaly. A scalar candidate (a Dark Higgs) cannot mediate the observed $^8$Be in the limit of conserved parity, which makes it not an ideal candidate \cite{PhysRevD.95.035017}. A pseudoscalar or ALP is likewise excluded if we consider only couplings to photons. The two main candidates not yet ruled out are the axial-vector and vector candidates, that we will explore here briefly. In this thesis, the focus will be on the vector candidate, that we will call $\DMX$ from now on. This is currently considered the most probable candidate for this anomaly, as the new result obtained for the $^4$He is well explained in this framework, while for the axial-vector case predicts a significant difference between decay widths of the two nuclei (factor $\sim10^2$) not observed in the experiment \cite{Feng:2020mbt}. Other explanations were proposed to justify this anomaly in particle physics, see for example \cite{Nam:2019osu, Seto:2016pks}.

We might be tempted to use directly the model developed in Sec.\ref{ch1:sec:dm-u1model} in its visible channel incarnation. However, this is not possible, as this model is already well excluded by the $\pi^0 \to \DM \gamma$ searches by NA48/2 \cite{na48}. Other simple extensions to this model, like a mixing with the SM $Z$ boson, or a light baryon-minus-lepton number (B - L) boson, are already constrained by several experiments \cite{PhysRevD.95.035017}. The current proposed solution is that the $\DMX$ disfavors coupling with protons. In mathematical terms, the relation $-0.067 < \epsilon_p/\epsilon_n < 0.078$ needs to be fulfilled to evade the current experimental limit, with the extreme scenario of $\epsilon_p = 0$ often taken as a benchmark to study the phenomenology of this particle. This protophobic gauge vector boson might look a bit arbitrary, but an example of such a particle can be found in the well-known $Z$ boson, which is protophobic at low energies \cite{PhysRevD.95.035017}. Recently, this model was criticized by pointing out that the production of $\DMX$ should be dominated by Dark Bremsstrahlung without going through any nuclear resonance for all proton beam energy above threshold, in direct contradiction with experimental observation \cite{zhang2020protophobic}.  However, in our experiment, the only assumption to be made is the existence of a coupling between $\DMX$ and the electron, which makes our sensitivity model-independent. This means our results can be easily extended to different models, like scalar, pseudo-scalar, and axial-vector boson. To cast the NA64 results, however, we will use the vector boson as a benchmark model.

A precise discussion of the values permitted for each coupling is discussed in \cite{Feng:2016jff,PhysRevD.95.035017}, here we will limit the discussion on the limit imposed to $\epsilon_e$ \footnote{Effectively one can interpret $\epsilon_e = \epsilon$ and use the model developed in Sec.\ref{ch1:sec:dm-u1model}}. For a lower limit of the coupling $\epsilon$, we know that $\DMX$ needs to decay within the experimental setup to be detected by the telescope. This turns out to give a weaker bound ($\gtrsim 10^{-5}$) than what is provided by beam dump experiments such as SLAC E141 \cite{blum} of $\gtrsim 2 \times 10^{-4}$. For the upper limit, a coupling too strong would influence the good agreement between the experiment and the theory of the anomalous magnetic moment of the electron. By combining the two results, we obtain:

\begin{equation}
  \label{eq:x17-limits}
  2 \times 10^{-5} < \epsilon_e < 1.4 \times 10^{-3}
\end{equation}

Which translates to a lifetime (see Eq.\ref{eq:dm-decay-length}) of the order of $10^{-14}\lesssim \tau_X \lesssim 10^{-12}$~s.

Interestingly, such a new boson with a relatively large coupling to charged leptons could also resolve the tension between measured and predicted values of the $(g - 2)_{\mu}$. Another interesting result comes from the new measurement of $\alpha$ performed by Parker \textit{et al.} \cite{Parker191} which combined with the $(g-2)_e$ measurements result in a 2.4 $\sigma$ deviation from the QED predictions \cite{PhysRevLett.100.120801}. Should this tension be confirmed, it would exclude the vector and axial-vector couplings explanation of $\DM$. On the other hand, models with nonzero V$\pm$A coupling constant with the electron would explain both electron and muon $(g - 2)$ anomalies \cite{Krasnikov:2019dgh}. In these models, the $\DMX$ could have a coupling of $6.8\cdot 10^{-4} \lesssim \epsilon \lesssim 9.6 \cdot 10^{-4}$ which leaves an interesting region of the parameter space to be explored. These models motivated the study of the phenomenological aspects of such a light vector boson weakly coupled to quarks and leptons (see, e.g., Refs.~\cite{fayet1, fayet2, fayet3, fayet4,jk, cheng, Zhang:2017zap, ia, liang, bart}) and new experimental searches (see e.g., Refs.~\cite{battaglieri2017cosmic, nardi}).

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../PhDthesis"
%%% End: